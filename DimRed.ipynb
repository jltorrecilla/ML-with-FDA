{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-weight: bold; color:#5D8AA8\" align=\"center\">\n",
    "    <div style=\"font-size: xx-large\">Machine Learning with Functional Data</div><br>\n",
    "    <div style=\"font-size: x-large; color:gray\">Dimensionality reduction</div><br>\n",
    "    <div style=\"font-size: large\">José Luis Torrecilla Noguerales - Universidad Autónoma de Madrid</div><br></div><hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial setting**: This cell defines the Notebook configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "    .qst {background-color: #b1cee3; padding:10px; border-radius: 5px; border: solid 2px #5D8AA8;}\n",
    "    .qst:before {font-weight: bold; content: \"Questions\"; display: block; margin: 0px 10px 10px 10px;}\n",
    "    h1, h2, h3 {color: #5D8AA8;}\n",
    "    .text_cell_render p {text-align: justify; text-justify: inter-word;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages to use:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skfda\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Principal Components Analysis (FPCA)\n",
    "### AEMET temperatures example \n",
    "\n",
    "As seen befor, **aemet** dataset consists of daily summaries from 73 spanish weather stations during the period 1980-2009. The dataset contains the geographic information of each station and the average for the period 1980-2009 of daily temperature, (log)precipitation and wind speed. For this example we only consider the temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, _ = skfda.datasets.fetch_aemet(return_X_y=True)\n",
    "\n",
    "X.plot()\n",
    "\n",
    "X = X.coordinates[0]\n",
    "X.plot() #Selecting temperatures only\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of principal components\n",
    "\n",
    "The class **[FPCA](https://fda.readthedocs.io/en/latest/modules/preprocessing/autosummary/skfda.preprocessing.dim_reduction.FPCA.html)** implements the techniques relatad to principal components analysis en *scikit-fda*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skfda.exploratory.visualization import FPCAPlot\n",
    "from skfda.preprocessing.dim_reduction import FPCA\n",
    "\n",
    "fpca_aemet = FPCA(n_components=2)   #Definition of FPCA object\n",
    "fpca_aemet.fit(X)             #Estimation of the principal components\n",
    "fpca_aemet.components_.plot()\n",
    "plt.legend(['PC1','PC2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal components and smoothing\n",
    "There are different ways to obtain smoother principal components. A first approach is to represent the trajectories in bases before applying FPCA. Remember that the components inherit the characteristics of the elements of the basis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "basis = skfda.representation.basis.BSplineBasis(n_basis=30)\n",
    "X_spline = X.to_basis(basis)\n",
    "X_spline.plot()\n",
    "\n",
    "fpca_aemet_s = FPCA(n_components=2)   #Definition of FPCA object\n",
    "fpca_aemet_s.fit(X_spline)            #Estimation of the principal components\n",
    "fpca_aemet_s.components_.plot()\n",
    "plt.legend(['PC1','PC2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Can we plot the first 4 principal components? Are they useful?\n",
    "* Can we obtain smooth components in a different way?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FPCAPlot(\n",
    "    X_spline.mean(),          #Sample mean of the original data\n",
    "    fpca_aemet_s.components_, #Principal components\n",
    "    factor=30,                #Scale factor to for the separation between curves.\n",
    "    fig=plt.figure(figsize=(6, 2 * 4)),\n",
    "    n_rows=2,\n",
    ").plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection and clustering\n",
    "\n",
    "\n",
    "Once the principal components have been calculated, we can use them to project the trajectories onto a lower-dimensional subspace of $\\mathbb{R}^d$. Then, we can use any multivariate methods we want with the reduced data.\n",
    "\n",
    "Let us point out that we are committing a slight abuse of notation by calling both the eigenfunctions that define the principal component basis and the projections of the data onto those directions \"components.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_red = fpca_aemet.transform(X) #Pojection\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(X_red[:,0], X_red[:,1])\n",
    "ax.set_xlabel('First principal component')\n",
    "ax.set_ylabel('Second principal component')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skfda.ml.clustering import KMeans\n",
    "from skfda.misc.metrics import l2_distance\n",
    "\n",
    "n_clusters = 5\n",
    "n_init = 10\n",
    "\n",
    "fda_kmeans = KMeans(\n",
    "    n_clusters=n_clusters,\n",
    "    n_init=n_init,\n",
    "    metric=l2_distance,\n",
    "    random_state=0,\n",
    ")\n",
    "fda_clusters = fda_kmeans.fit_predict(X)\n",
    "\n",
    "# Colors for each cluster\n",
    "fda_color_map = {\n",
    "    0: \"purple\",\n",
    "    1: \"yellow\",\n",
    "    2: \"green\",\n",
    "    3: \"red\",\n",
    "    4: \"orange\",\n",
    "}\n",
    "\n",
    "# Names of each climate (for this particular seed)\n",
    "climate_names = {\n",
    "    0: \"Cold-mountain\",\n",
    "    1: \"Mediterranean\",\n",
    "    2: \"Atlantic\",\n",
    "    3: \"Subtropical\",\n",
    "    4: \"Continental\",\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for cluster in range(n_clusters):\n",
    "    selection = fda_clusters == cluster\n",
    "    ax.scatter(\n",
    "        -X_red[selection, 0],\n",
    "        -X_red[selection, 1],\n",
    "        color=fda_color_map[cluster],\n",
    "        label=climate_names[cluster],\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('First principal component')\n",
    "ax.set_ylabel('Second principal component')\n",
    "ax.legend()\n",
    "\n",
    "X_red_s = fpca_aemet_s.transform(X_spline)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for cluster in range(n_clusters):\n",
    "    selection = fda_clusters == cluster\n",
    "    ax.scatter(\n",
    "        -X_red_s[selection, 0],\n",
    "        -X_red_s[selection, 1],\n",
    "        color=fda_color_map[cluster],\n",
    "        label=climate_names[cluster],\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Smooth first principal component')\n",
    "ax.set_ylabel('Smooth second principal component')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPCA and classification\n",
    "For this example, we will use the growth curves from the Berkeley study. The objective will be to correctly classify girls and boys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Berkeley growth study dataset\n",
    "X, y = skfda.datasets.fetch_growth(return_X_y=True)\n",
    "X.plot(group=y)\n",
    "\n",
    "\n",
    "fpca_growth = FPCA(n_components=2)   #Definition of FPCA object\n",
    "fpca_growth.fit(X)             #Estimation of the principal components\n",
    "fpca_growth.components_.plot()\n",
    "plt.legend(['PC1','PC2'])\n",
    "\n",
    "X_red = fpca_growth.transform(X) #Projection\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(X_red[:,0], X_red[:,1], c=y)\n",
    "ax.set_xlabel('First principal component')\n",
    "ax.set_ylabel('Second principal component')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to study the difference between using the reduced data with FPCA and a multivariate classifier versus using the complete trajectories with a functional classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from skfda.ml.classification import KNeighborsClassifier as fKNN\n",
    "\n",
    "#FPCA + multivariate k-NN with Euclidean distance\n",
    "knn = KNN()\n",
    "gcv = GridSearchCV(knn, {'n_neighbors':range(1,9,2)})\n",
    "gcv.fit(X_red,y)\n",
    "print('k-nn cv accuracy with the reduced data:',\"{:.4f}\".format(gcv.best_score_))\n",
    "\n",
    "#Functional k-NN with L2 distance\n",
    "fknn = fKNN()\n",
    "gcvf = GridSearchCV(fknn, {'n_neighbors':range(1,9,2)})\n",
    "gcvf.fit(X,y)\n",
    "print('Functional k-nn cv accuracy with the oritinal trajectories:',\"{:.4f}\".format(gcvf.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gcv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "    \n",
    "* What is the reason why we always obtain the same values when running the code again? \n",
    "    \n",
    "* Try to vary the number of principal components. What happends? How to choose the best value?\n",
    "</div>\n",
    "\n",
    "If you want to randomize the partitios, pass a \"StratifiedKFold\" object with the parameter \"shuffle=True\" (and optionally, a seed in the \"random_state\" parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import skfda\n",
    "from skfda.preprocessing.dim_reduction import FPCA\n",
    "\n",
    "fpca = FPCA()\n",
    "classifier = GridSearchCV(KNN(), {'n_neighbors':range(1,7,2)})  # You can choose your favourite classifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"fpca\", fpca),\n",
    "    (\"classifier\", classifier),\n",
    "])\n",
    "\n",
    "pipe_gcv = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid={'fpca__n_components': range(1, 11)}\n",
    ")\n",
    "\n",
    "pipe_gcv.fit(X, y)\n",
    "print('k-nn cv accuracy with the reduced data:',\"{:.4f}\".format(pipe_gcv.best_score_))\n",
    "print(pipe_gcv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It is important to note that this hyperparameter selection approach is inefficient: for each number of components, FPCA is recalculated. It is possible to create a more efficient version by having FPCA return the maximum number of components and introducing a third element in the pipeline that selects the necessary number of components and caches the results, similar to [this example for the multivariate case](https://github.com/scikit-learn/scikit-learn/issues/19649#issuecomment-793282436)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skfda.preprocessing.dim_reduction import variable_selection as vs\n",
    "\n",
    "#Variable selection\n",
    "rkvs = vs.RKHSVariableSelection(n_features_to_select=2)\n",
    "rkvs.fit(X,y)\n",
    "\n",
    "#get the impact points\n",
    "point_mask = rkvs.get_support()\n",
    "points = X.grid_points[0][point_mask]\n",
    "print(points)\n",
    "\n",
    "#Projection and plotting\n",
    "X_rkvs = rkvs.transform(X)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(X_rkvs[:,0], X_rkvs[:,1], c=y)\n",
    "ax.set_xlabel('First variable')\n",
    "ax.set_ylabel('Second variable')\n",
    "plt.show()\n",
    "\n",
    "#Classification\n",
    "knn = KNN()\n",
    "gcv = GridSearchCV(knn, {'n_neighbors':range(1,9,2)})\n",
    "gcv.fit(X_rkvs,y)\n",
    "print('k-nn cv accuracy with the reduced data:',\"{:.4f}\".format(gcv.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "    \n",
    "* Is this procedure for estimating classification error correct?\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
