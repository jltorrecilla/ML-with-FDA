{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-weight: bold; color:#5D8AA8\" align=\"center\">\n",
    "    <div style=\"font-size: xx-large\">Machine Learning with Funcitonal Data</div><br>\n",
    "    <div style=\"font-size: x-large; color:gray\">Introduction to FDA with scikit-fda</div><br>\n",
    "    <div style=\"font-size: large\">José Luis Torrecilla Noguerales - Universidad Autónoma de Madrid</div><br></div><hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial setting**: This cell defines the Notebook setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "    .qst {background-color: #b1cee3; padding:10px; border-radius: 5px; border: solid 2px #5D8AA8;}\n",
    "    .qst:before {font-weight: bold; content: \"Questions\"; display: block; margin: 0px 10px 10px 10px;}\n",
    "    h1, h2, h3 {color: #5D8AA8;}\n",
    "    .text_cell_render p {text-align: justify; text-justify: inter-word;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages to use:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skfda\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The class FDataGrid\n",
    "## Defining the [FDataGrid](https://fda.readthedocs.io/en/latest/modules/autosummary/skfda.representation.grid.FDataGrid.html#skfda.representation.grid.FDataGrid)\n",
    "\n",
    "The main attributes when defining dataset of discretized functional data are **grid_points** and **data_matrix** which stand for the array of discretization points $t_1,\\ldots,t_M$, and the matrix with the values of the $N$ trajectories evaluated at the grid points (one observation per row).  the values of the trajectories at the grid points. \n",
    "\n",
    "Note that the grid points can be omitted, and in that case, they are automatically assigned as equispaced points in domain set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_points = [0.0, 0.2, 0.4, 0.5, 0.6, 1.0]  # Grid points of the curves\n",
    "data_matrix = [\n",
    "    [0.00, 0.20, 0.50, 0.90, 1.20, 1.00],  # First observation\n",
    "    [0.00, 0.04, 0.25, 0.75, 0.85, 1.00],  # Second observation\n",
    "    [0.25, 0.00, 1.00, 0.00, 0.50, 1.00],  # Third observation\n",
    "]\n",
    "\n",
    "fd = skfda.FDataGrid(\n",
    "#    grid_points=grid_points,\n",
    "    data_matrix=data_matrix\n",
    ")\n",
    "\n",
    "fd.scatter(s=0.3) #Discretized values\n",
    "plt.show()\n",
    "\n",
    "fig = fd.plot() #Interpolated functions. Depends on the interpolation attribute\n",
    "fd.scatter(fig=fig)\n",
    "plt.show()\n",
    "fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples in higher dimensions\n",
    "\n",
    "We will load the digits dataset from *scikit-learn*, which contains images of the digits from $0$ to $9$. This can be loaded with [load_digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits), returning a NumPy array. We can view this digits as surfaces, that is, functions $x(s,t):\\mathbb{R}^2 \\longrightarrow\\mathbb{R}$. The problem is that the data has been flattened into a 1D vector of pixels, so first, we need to reshape them to their original 8x8 shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directive to get interactive plots\n",
    "#Package ipympl is needed. You need to install the package once with !pip install ipympl\n",
    "%matplotlib widget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "print(X.shape)\n",
    "X = X.reshape(-1, 8, 8)\n",
    "print(X.shape)\n",
    "\n",
    "fd2 = skfda.FDataGrid(X)\n",
    "\n",
    "# Plot the first 2 observations\n",
    "fd2[0].plot()\n",
    "plt.show()\n",
    "fd2[7].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation and Extrapolation\n",
    "\n",
    "For the evaluation between the points of discretization, or sample points, is necessary to interpolate. By default it is used linear interpolation, which is one of the simplest methods of interpolation and therefore one of the least computationally expensive, but has the disadvantage that the interpolant is not differentiable at the points of discretization.\n",
    "\n",
    "The interpolation method of the *FDataGrid* could be changed setting the **attribute interpolation**. Once we have set an interpolation it is used for the evaluation of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfda.representation.interpolation import SplineInterpolation\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 2.5))\n",
    "\n",
    "\n",
    "fd.scatter(axes[0],s=0.3) #Discretized values\n",
    "\n",
    "fd.plot(axes[1]) #Interpolated functions. Depends on the interpolation attribute (linear by default)\n",
    "fd.scatter(axes[1])\n",
    "\n",
    "#Polynomial interpolation\n",
    "fd.interpolation = SplineInterpolation(interpolation_order=3)\n",
    "\n",
    "fd.plot(axes[2])\n",
    "fd.scatter(axes[2])\n",
    "fig.suptitle(None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* How does interpolation affect surfaces? Let's consider the example of digits.\n",
    "    \n",
    "* What happens when we change the interpolation order of B-splines to 0?\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrapolation refers to the process of estimating values beyond the range of available data.  The extrapolation criterion can be specified when the object is created or changing the **attribute extrapolation**.\n",
    "\n",
    "If the extrapolation is not specified when a list of points is evaluated and the default extrapolation of the objects has not been specified it is used the type “none”, which will evaluate the points outside the domain without any kind of control.\n",
    "\n",
    "For this reason the behavior outside the domain will change depending on the representation, obtaining a periodic behavior in the case of the Fourier basis and polynomial behaviors in the rest of the cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_extended = (-0.2, 1.2)\n",
    "\n",
    "fd.extrapolation = \"None\" #Default extrapolation strategy\n",
    "fig = fd.plot(domain_range=domain_extended, linestyle=\"--\")\n",
    "plt.gca().set_prop_cycle(None) \n",
    "fd.plot(fig=fig)\n",
    "plt.show()\n",
    "\n",
    "fd.extrapolation = \"bounds\" \n",
    "fig = fd.plot(domain_range=domain_extended, linestyle=\"--\")\n",
    "plt.gca().set_prop_cycle(None) \n",
    "fd.plot(fig=fig)\n",
    "plt.show()\n",
    "\n",
    "fd.extrapolation = \"periodic\"\n",
    "fig = fd.plot(domain_range=domain_extended, linestyle=\"--\")\n",
    "plt.gca().set_prop_cycle(None) \n",
    "fd.plot(fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading functional datasets: the fetch functions\n",
    "### Common datasets\n",
    "\n",
    "Some commonly used datasets have their own fetch functions. Here we explore **aemet**, wich consists of daily summaries from 73 spanish weather stations during the period 1980-2009. The dataset contains the geographic information of each station and the average for the period 1980-2009 of daily temperature, (log)precipitation and wind speed. This can be seen as an example o the so-called multivariate functional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = skfda.datasets.fetch_aemet(return_X_y=True)\n",
    "\n",
    "print(repr(X)) #repr returns a more detailed descrition of the object\n",
    "\n",
    "X.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding some interactivity\n",
    "from matplotlib.widgets import Slider\n",
    "\n",
    "graph_plot = skfda.exploratory.visualization.representation.GraphPlot(X)\n",
    "interactive_plot = skfda.exploratory.visualization.MultipleDisplay(\n",
    "    [graph_plot],           #plots included\n",
    "    criteria=range(len(X)), #\n",
    "    sliders=Slider,\n",
    "    label_sliders=[\"ID\"]\n",
    ")\n",
    "interactive_plot.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X.coordinates[0].plot() #Selecting temperatures only\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets from repositories\n",
    "\n",
    "There are functional datasets in many repositories. Functions **fetch_cran** and **fetch_ucr** make it easy for us to access data in in the CRAN repository (R), and in the UEA & UCR Time Series Classification Repository repositories, respectively. Note these datasets do not follow a particular structure, so you will need to know how it is structured internally in order to use it properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = skfda.datasets.fetch_ucr(\"GunPoint\", return_X_y=True)\n",
    "X.plot(group=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of random trajectories\n",
    "ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfda.misc.covariances import Brownian\n",
    "\n",
    "fd = skfda.datasets.make_gaussian_process(\n",
    "start = 0,                 #initial point\n",
    "stop = 1,                   #final point\n",
    "n_samples=10,               #sample size\n",
    "n_features=100,             #number of variables/discretization points\n",
    "mean=0,        #mean function. lambda function f(t) = t^2\n",
    "cov=Brownian(variance=1),   #covariance function\n",
    "random_state=0              #seed\n",
    ")\n",
    "\n",
    "fd.plot() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Try to draw 10 trajectories of a standard Brownian motion.\n",
    "    \n",
    "    \n",
    "* Do you know how to compute $5^2$ using lambda functions?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brownian() #Interaction with jupyter (prototype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The class FDataBasis\n",
    "### From FDataGrid to FDataBasis\n",
    "The method **to_basis()** transform FDataGrid objects to a basis representation (FDataBasis). The desired basis must be passed as an argument.  you will need to call the method to_basis, passing the desired basis as an argument. The discretized trajectories will be projected to the functional basis by solving a least squares problem in order to find the optimal coefficients of the expansion. \n",
    "The reciprocal action can be dan with **to_grid**. This method evaluates the functions in a grid supplied as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = skfda.datasets.fetch_phoneme(return_X_y=True)\n",
    "\n",
    "X = X[:5] # Select only the first 5 observations\n",
    "\n",
    "X.plot()\n",
    "plt.show()\n",
    "\n",
    "#B-Spline basis. The parameter order refers to the degree of the polynomials plus 1.\n",
    "basis = skfda.representation.basis.BSplineBasis(n_basis=8, order=4)\n",
    "X.to_basis(basis).plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "\n",
    "* Explore the effect of varying the number of elements in the basis and the type of basis.\n",
    "* What happens if we extrapolate the basis set to the interval (-1,10)? How does extrapolation behave when we change the basis?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing\n",
    "### Kernel smoothing\n",
    "Although the basis representation results in the smoothing of the trajectories, there are other smoothing techniques that do not require the use bases. Perhaps the most popular are those based on kernels like Nadaraya-Watson or near neighbors. Some of these methods are available in the scikit-fda's class **KernelSmoother**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skfda.misc.hat_matrix import (\n",
    "    KNeighborsHatMatrix,\n",
    "    NadarayaWatsonHatMatrix\n",
    ")\n",
    "\n",
    "from skfda.preprocessing.smoothing import KernelSmoother\n",
    "\n",
    "X_s = KernelSmoother(\n",
    "    kernel_estimator=NadarayaWatsonHatMatrix(bandwidth=0.5),\n",
    ").fit_transform(X)\n",
    "\n",
    "\n",
    "X_s = KernelSmoother(\n",
    "    kernel_estimator=KNeighborsHatMatrix(n_neighbors=50),\n",
    ").fit_transform(X)\n",
    "\n",
    "X_s.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "    \n",
    "* What happens when varying the bandwith parameter?\n",
    "    \n",
    "* Try Nearest neighbors kernel. What happens with large values of $k$?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandwith selection\n",
    "Let's build a synthetic example to see clearly the effects of overfitting and oversmoothing. The example will be a sinusoidal trajectory with some noise and our objective will be to recover the original signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfda.datasets import make_sinusoidal_process\n",
    "\n",
    "#Original trajectory, without noise\n",
    "x_original = make_sinusoidal_process(\n",
    "    n_samples=1,\n",
    "    n_features=20,\n",
    "    error_std=0,\n",
    "    random_state=1)\n",
    "fig = x_original.plot()\n",
    "\n",
    "#Noisy trajectory\n",
    "x_noisy = make_sinusoidal_process(\n",
    "    n_samples=1,\n",
    "    n_features=20,\n",
    "    error_std=0.2,\n",
    "    random_state=1)\n",
    "x_noisy.scatter(fig=fig)\n",
    "x_noisy.plot(fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = x_original.plot()\n",
    "x_noisy.scatter(fig=fig)\n",
    "\n",
    "#Underfitting - oversmoothing\n",
    "x_s1 = KernelSmoother(\n",
    "    kernel_estimator=NadarayaWatsonHatMatrix(bandwidth=0.3),\n",
    ").fit_transform(x_noisy)\n",
    "x_s1.plot(fig=fig)\n",
    "\n",
    "#Overfitting - undersmoothing\n",
    "x_s2 = KernelSmoother(\n",
    "    kernel_estimator=NadarayaWatsonHatMatrix(bandwidth=0.05),\n",
    ").fit_transform(x_noisy)\n",
    "x_s2.plot(fig=fig)\n",
    "\n",
    "fig.legend(\n",
    "    [\n",
    "        'original trajectory',\n",
    "        'noisy observations',\n",
    "        'Underfitting',\n",
    "        'Overfitting',\n",
    "    ]    \n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized cross-validation\n",
    "In general, we do not know the best value for the smoothing parameter, and trial and error is not the best solution. There are cross-validation techniques to automate the choice of the bandwith by minimizing certain objective functions. In the case of scikit-fda we can use a [generalized cross validation](https://fda.readthedocs.io/en/latest/modules/preprocessing/autosummary/skfda.preprocessing.smoothing.validation.LinearSmootherGeneralizedCVScorer.html#skfda.preprocessing.smoothing.validation.LinearSmootherGeneralizedCVScorer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfda.preprocessing.smoothing.validation import SmoothingParameterSearch\n",
    "from skfda.preprocessing.smoothing.validation import akaike_information_criterion, LinearSmootherGeneralizedCVScorer\n",
    "import numpy as np\n",
    "\n",
    "# Defining grid search\n",
    "bandwidth = np.linspace(0.01, 1, 100)\n",
    "\n",
    "\n",
    "# Nadaraya-Watson kernel smoother\n",
    "nw = SmoothingParameterSearch(\n",
    "    KernelSmoother(kernel_estimator=NadarayaWatsonHatMatrix()),\n",
    "    bandwidth,\n",
    "    scoring=LinearSmootherGeneralizedCVScorer(penalization_function=lambda t:1),\n",
    "    param_name='kernel_estimator__bandwidth'\n",
    ")\n",
    "\n",
    "# Fit and transform must be done separately since SmoothingParameterSearch\n",
    "# object do not have fit_transform method\n",
    "nw.fit(x_noisy)\n",
    "x_opt = nw.transform(x_noisy)\n",
    "\n",
    "\n",
    "fig = x_original.plot()\n",
    "x_noisy.scatter(fig=fig)\n",
    "x_opt.plot(fig=fig)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0.01, 1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"qst\">\n",
    "    \n",
    "* Is it possible to obtain a better fit?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivatives\n",
    "The computation of derivatives is of particular importance in functional data analysis. In the scikit-fda package, the method derivative() can be used to per-\n",
    "form this operation for both FDataGrid and FDataBasis objects. In the case of FDataGrid\n",
    "objects, derivatives are approximated using finite differences. For FDataBasis objects, they\n",
    "are computed exactly in terms of the derivatives of the basis functions. Therefore, if a new\n",
    "type of basis is designed, it is necessary to implement the derivatives of the basis functions in\n",
    "the corresponding class.\n",
    "\n",
    "Here, we illustrate the use of the derivatives with the popular Tecator dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = skfda.datasets.fetch_tecator(return_X_y=True)\n",
    "y = y[:, 0] # keeping only the fat content as target variable\n",
    "\n",
    "X.plot(gradient_criteria=y)\n",
    "plt.show()\n",
    "\n",
    "X_der = X.derivative(order=2) #Second derivative by finite differences\n",
    "X_der.plot(gradient_criteria=y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
